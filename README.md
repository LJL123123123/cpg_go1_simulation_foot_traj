# CPG-Go1 Simulation

[![DOI](https://img.shields.io/badge/DOI-10.48550/arXiv.2406.13419-blue)](https://doi.org/10.48550/arXiv.2406.13419)

<img width="3315" height="1079" alt="image" src="https://github.com/user-attachments/assets/8c195982-b5cf-4f2d-b470-86d6564ab5b7" />

## Citation

If you use this work in your research, please cite:

```bibtex
@article{liu2024eight,
  title={An eight-neuron network for quadruped locomotion with hip-knee joint control},
  author={Liu, Yide and Liu, Xiyan and Wang, Dongqi and Yang, Wei and Qu, Shaoxing},
  journal={The International Journal of Robotics Research},
  pages={02783649251364286},
  publisher={SAGE Publications Sage UK: London, England}
}
```
A comprehensive simulation framework for quadruped robot locomotion based on Central Pattern Generator (CPG) networks and neural execution control for the Unitree Go1 robot.

## Overview

This project implements a biologically-inspired locomotion control system for quadruped robots, combining:

- **Central Pattern Generator (CPG)**: 8-neuron Stein oscillator network for rhythmic gait generation
- **Neural Execution Network**: Multi-layer perceptron (MLP) for translating CPG states to joint commands
- **Sensory Feedback System**: Real-time sensor integration for adaptive locomotion control
- **Physics Simulation**: High-fidelity PyBullet-based simulation environment

### Key Features

- ğŸ¦¾ **Multi-Gait Support**: Walk, trot, pace, bound, and pronk gaits
- ğŸ”„ **Smooth Gait Transitions**: Four transition strategies (Switch, Power Pair, Wait&Switch, Wait&Power Pair)
- ğŸ¯ **Sensory Feedback**: IMU, camera, and contact sensor integration
- ğŸƒâ€â™‚ï¸ **Adaptive Control**: Real-time CPG parameter adjustment based on environmental feedback
- ğŸ® **Multiple Environments**: Flat terrain, slopes, and figure-8 path following

## Project Structure

```
cpg_go1_simulation/
â”œâ”€â”€ src/cpg_go1_simulation/                            # Core package
â”‚   â”œâ”€â”€ config.py                                      # Configuration files and constants
â”‚   â”œâ”€â”€ execution_neural_network/                      # Execution neural network
â”‚   â”‚   â””â”€â”€ mlp.py                                     # Mlp network
â”‚   â”œâ”€â”€ gait_and_transition/                           # Gait and gait transition
â”‚   â”‚   â”œâ”€â”€ export_cpg.py                              # CPG data generation
â”‚   â”‚   â””â”€â”€ process_network.py                         # CPG-to-joint mapping
â”‚   â”œâ”€â”€ sensor/                                        # Sensor-based control
â”‚   â”‚   â”œâ”€â”€ Quadruped_model/                           # Go1 robot model files and ground model
â”‚   â”‚   â”œâ”€â”€ quadruped_robot.py                         # Robot simulation environment
â”‚   â”‚   â”œâ”€â”€ realtime_controller.py                     # Real-time controller
â”‚   â”‚   â”œâ”€â”€ robot_controller.py                        # Basic controller
â”‚   â”‚   â”œâ”€â”€ sensor.py                                  # IMU and RGB Carame sensor
â”‚   â”‚   â”œâ”€â”€ reflexion_processor.py                     # Reflexion processor
â”‚   â”‚   â””â”€â”€ visual_processor_rgb.py                    # Vision-based processor
â”‚   â””â”€â”€ stein/                                         # CPG network implementation
â”‚       â”œâ”€â”€ base.py                                    # Abstract CPG base class
â”‚       â””â”€â”€ implementations.py                         # 8-neuron CPG implementation
â”œâ”€â”€ examples/                                          # Demo scripts
â”‚   â”œâ”€â”€ demo_video3_gait.py                            # Basic gait demonstration
â”‚   â”œâ”€â”€ demo_video4_gait_transition.py                 # Gait transition demo
â”‚   â”œâ”€â”€ demo_video5_sensory_feedback_path_following.py # Path following
â”‚   â”œâ”€â”€ demo_video6_sensory_feedback_reflex.py         # Reflex loop
â”‚   â””â”€â”€ demo_video7_backward_control.py                # Backward locomotion
â”œâ”€â”€ data/                                              # Generated data storage
â”œâ”€â”€ resources/                                         # Pre-trained models
â”‚   â””â”€â”€ best_model/                                    # Neural network model
â””â”€â”€ pyproject.toml                                     # Project configuration
```

## Installation

### Prerequisites

- Python 3.12 or higher
- Git

### Quick Start

1. **Clone the repository**:
   ```bash
   git clone https://github.com/imdipsy/cpg_go1_simulation.git
   cd cpg_go1_simulation
   ```

2. **Install the package in development mode**:
   ```bash
   pip install -e .
   ```

3. **Verify installation** by running a demo:
   ```bash
   python examples/demo_video3_gait.py
   ```


## Quick Start Examples

### 1. Basic Gait Simulation

Run a simple trot gait simulation:

```bash
python examples/demo_video3_gait.py
```

### 2. Gait Transitions

Demonstrate smooth transitions between gaits:

```bash
python examples/demo_video4_gait_transition.py
```


### 3. Sensory Feedback Control

####  Path following using camera
Run adaptive control with sensor feedback:

```bash
python examples/demo_video5_sensory_feedback_path_following.py
```

#### Gait transition via reflex loop
```bash
python examples/demo_video6_sensory_feedback_reflex.py
```
### 4. Backward Locomotion
```bash
python examples/demo_video7_backward_control.py
```

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## Support

- ğŸ“§ **Email**: dipsy@zju.edu.cn(Xiyan Liu), yide_liu@zju.edu.cn(Yide Liu)
- ğŸ› **Issues**: [GitHub Issues](https://github.com/imdipsy/cpg_go1_simulation/issues)


